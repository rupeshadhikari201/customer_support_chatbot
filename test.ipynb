{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db57b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai langchain-community langchain-cohere langchain-mistralai faiss-cpu rank-bm25 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a94726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['COHERE_API_KEY'] = 'WbDwiNgZambTJnI3Uwq8nr5LZ5P5AJn8lPWjWnrI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b9d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class OptimizedRAGPipeline:\n",
    "    def __init__(self,\n",
    "                 docs_path: str = 'doc/',\n",
    "                 chunk_size: int = 2000,\n",
    "                 chunk_overlap: int = 200,\n",
    "                 embedding_model: str = 'embed-english-v3.0',\n",
    "                 use_reranker: bool = True,\n",
    "                 use_compression: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the optimized RAG pipeline\n",
    "\n",
    "        Args:\n",
    "            docs_path (str): Path to the documents directory\n",
    "            chunk_size (int): Size of document chunks\n",
    "            chunk_overlap (int): Overlap between chunks\n",
    "            embedding_model (str): Cohere embedding model name (note: uses 'model' parameter in newer versions)\n",
    "            use_reranker (bool): Whether to use reranking\n",
    "            use_compression (bool): Whether to use contextual compression\n",
    "        \"\"\"\n",
    "        self.docs_path = docs_path\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.embedding_model = embedding_model\n",
    "        self.use_reranker = use_reranker\n",
    "        self.use_compression = use_compression\n",
    "\n",
    "        # Initialize components\n",
    "        self.documents = self._load_documents()\n",
    "        self.embeddings = self._initialize_embeddings()\n",
    "        self.vector_store = self._create_vector_store()\n",
    "        self.retriever = self._build_retriever()\n",
    "\n",
    "    def _load_documents(self) -> List[Document]:\n",
    "        \"\"\"Load and split documents from the specified path\"\"\"\n",
    "\n",
    "        try:\n",
    "            # Load documents from directory\n",
    "            loader = DirectoryLoader(\n",
    "                self.docs_path,\n",
    "                glob='*.txt',\n",
    "                loader_cls=TextLoader,\n",
    "                loader_kwargs={\"encoding\": \"utf-8\"}\n",
    "            )\n",
    "\n",
    "            # Split documents with optimized chunking strategy\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=self.chunk_size,\n",
    "                chunk_overlap=self.chunk_overlap,\n",
    "                separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "                length_function=len\n",
    "            )\n",
    "\n",
    "            documents = loader.load_and_split(text_splitter)\n",
    "\n",
    "            return documents\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            return []\n",
    "\n",
    "    def _initialize_embeddings(self):\n",
    "        \"\"\"Initialize the embedding model\"\"\"\n",
    "\n",
    "        try:\n",
    "            return CohereEmbeddings(model=self.embedding_model)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                return CohereEmbeddings(model=self.embedding_model)\n",
    "            except Exception as fallback_error:\n",
    "                return CohereEmbeddings(model=self.embedding_model)\n",
    "\n",
    "    def _create_vector_store(self):\n",
    "        \"\"\"Create a vector store from documents and embeddings\"\"\"\n",
    "\n",
    "        try:\n",
    "            return FAISS.from_documents(self.documents, self.embeddings)\n",
    "        except Exception as e:\n",
    "\n",
    "            return None\n",
    "\n",
    "    def _build_retriever(self, k: int = 3):\n",
    "        \"\"\"Build an optimized retriever with multiple strategies\"\"\"\n",
    "\n",
    "        # Create base vector retriever\n",
    "        vector_retriever = self.vector_store.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "        # Create BM25 retriever for keyword-based retrieval\n",
    "        bm25_retriever = BM25Retriever.from_documents(self.documents)\n",
    "        bm25_retriever.k = k\n",
    "\n",
    "        # Combine retrievers with weights\n",
    "        ensemble_retriever = EnsembleRetriever(\n",
    "            retrievers=[vector_retriever, bm25_retriever],\n",
    "            weights=[0.7, 0.3]\n",
    "        )\n",
    "\n",
    "        # Add contextual compression if enabled\n",
    "        if self.use_compression:\n",
    "            try:\n",
    "                try:\n",
    "                    from langchain_cohere import ChatCohere\n",
    "                    llm = ChatCohere(\n",
    "                        cohere_api_key=os.environ.get('COHERE_API_KEY'),\n",
    "                        temperature=0\n",
    "                    )\n",
    "                except Exception:\n",
    "                    print(\"Error in contextual compression\")\n",
    "\n",
    "                compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "                return ContextualCompressionRetriever(\n",
    "                    base_compressor=compressor,\n",
    "                    base_retriever=ensemble_retriever\n",
    "                )\n",
    "            except Exception as e:\n",
    "                return ensemble_retriever\n",
    "        else:\n",
    "            return ensemble_retriever\n",
    "\n",
    "    def retrieve(self, query: str, k: int = 3) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query\n",
    "            k (int): Number of documents to retrieve\n",
    "\n",
    "        Returns:\n",
    "            List[Document]: List of retrieved documents\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # Use the new invoke method instead of deprecated get_relevant_documents\n",
    "            return self.retriever.invoke(query)\n",
    "        except Exception as e:\n",
    "\n",
    "            # Fallback to simple vector retrieval if ensemble fails\n",
    "            try:\n",
    "                return self.vector_store.similarity_search(query, k=k)\n",
    "            except Exception as inner_e:\n",
    "                return []\n",
    "\n",
    "    def get_retrieval_content(self, query: str, k: int = 3) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get the content of retrieved documents for a query\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query\n",
    "            k (int): Number of documents to retrieve\n",
    "\n",
    "        Returns:\n",
    "            List[str]: List of document contents\n",
    "        \"\"\"\n",
    "        docs = self.retrieve(query, k)\n",
    "        return [doc.page_content if doc.page_content != 'NO_OUTPUT.' else '' for doc in docs]\n",
    "\n",
    "\n",
    "# Initialize the RAG pipeline\n",
    "rag_pipeline = OptimizedRAGPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750d65e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'doc\\\\faq.txt'}, page_content='### 1. \"How do I reset my password?\"\\nTo reset your password on GOKAP InnoTech:\\n1. Click on the \"Login\" button at the top right of the homepage\\n2. Select \"Forgot Password\" below the login form\\n3. Enter the email address associated with your account\\n4. Check your email inbox for a password reset link (check spam/junk folders if not visible)\\n5. Click the link and follow instructions to create a new password\\n6. Use your new password to log in\\n\\nIf you don\\'t receive the reset email within 10 minutes, you can contact our support team at support@gokapinnotech.com for assistance.'),\n",
       " Document(metadata={'source': 'doc\\\\main_corpus.txt'}, page_content='NO_OUTPUT.'),\n",
       " Document(metadata={'source': 'doc\\\\faq.txt'}, page_content='NO_OUTPUT.'),\n",
       " Document(metadata={'source': 'doc\\\\faq.txt'}, page_content='NO_OUTPUT.'),\n",
       " Document(metadata={'source': 'doc\\\\faq.txt'}, page_content='NO_OUTPUT.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve = rag_pipeline.retrieve('How do I reset my password on GOKAP InnoTech')\n",
    "retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ff6b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['### 1. \"How do I reset my password?\"\\nTo reset your password on GOKAP InnoTech:\\n1. Click on the \"Login\" button at the top right of the homepage\\n2. Select \"Forgot Password\" below the login form\\n3. Enter the email address associated with your account\\n4. Check your email inbox for a password reset link (check spam/junk folders if not visible)\\n5. Click the link and follow instructions to create a new password\\n6. Use your new password to log in\\n\\nIf you don\\'t receive the reset email within 10 minutes, you can contact our support team at support@gokapinnotech.com for assistance.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_content = rag_pipeline.get_retrieval_content('How do I reset my password on GOKAP InnoTech')\n",
    "retrieval_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ced7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "llm = ChatCohere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a6d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "  \"You are a helpful customer support assistant for gokap innotech company. \"\n",
    "  \"Your goal is to provide accurate, helpful, and concise responses based on the company's knowledge base. \"\n",
    "  Asked Question = {question}\n",
    "  Retrived Context = {context}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dddc851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = rag_pipeline.get_retrieval_content\n",
    "\n",
    "chain = (\n",
    "    {\"context\" : retriever, \"question\" : RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e623f627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To reset your password on GOKAP InnoTech, follow these steps:\\n\\n1. **Click on the \"Login\" button** at the top right of the homepage.  \\n2. **Select \"Forgot Password\"** below the login form.  \\n3. **Enter the email address** associated with your account.  \\n4. **Check your email inbox** for a password reset link (also check spam/junk folders if it’s not visible).  \\n5. **Click the link** and follow the instructions to create a new password.  \\n6. **Use your new password** to log in.  \\n\\nIf you don’t receive the reset email within 10 minutes, please contact our support team at **support@gokapinnotech.com** for assistance. Let me know if you need further help!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = chain.invoke(\"How do I reset my password on GOKAP InnoTech\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd33e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-openai -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73ecedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f15e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"https://ai-22bca102665700ai188063459630.openai.azure.com/\"\n",
    "model_name = \"gpt-35-turbo-16k\"\n",
    "deployment = \"gpt-35-turbo-16k\"\n",
    "subscription_key = \"3rvBCoNuhTcQPmC7xgwiHY72VMcbzGxzwuWSMbWJsPcsIuJ8JtuDJQQJ99BDACHYHv6XJ3w3AAAAACOGuUwO\"\n",
    "api_version = \"2024-12-01-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2552d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_llm = AzureChatOpenAI(\n",
    "    deployment_name=deployment,\n",
    "    api_version= api_version,\n",
    "    model='gpt-35-turbo-16k',\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91d8b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ragas -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c02ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample, EvaluationDataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
